You've configured security principals that define *who* can access your AI resources. Now you need to establish *where* those permissions apply and *how* policies cascade through your infrastructure. Azure's scope hierarchy—Management Groups, Subscriptions, Resource Groups, and Resources—provides the organizational framework that makes this possible. Unlike a flat permission model where you'd manage access to hundreds of individual resources, Azure's hierarchy lets you assign policies once at a higher scope and watch them automatically apply to everything below.

Consider how this mirrors familiar file system organization. Management Groups sit at the top like drive letters, representing your entire organization or major business divisions. Subscriptions nest within management groups like top-level folders, typically separating environments (production, development, testing) or business units (sales, marketing, operations). Resource Groups function like project folders, collecting related AI resources that share a common lifecycle—all components for your customer sentiment analysis project live together in one resource group. Finally, individual Resources are the files themselves: specific ML workspaces, storage accounts, and AI service instances. This hierarchical structure becomes powerful when combined with inheritance: assign a policy at the management group level, and it flows down through subscriptions, resource groups, and ultimately applies to every individual resource.

:::image type="content" source="../media/azure-subscriptions-nest-management-groups.png" alt-text="Diagram showing how subscriptions nest within management groups like top-level folders.":::

With this foundation in place, let's explore how your AI platform maps to this hierarchy. Suppose your organization runs AI workloads across three business units: retail analytics, fraud detection, and customer service automation. You create a management group called "AI Platform" that contains organization-wide policies like "All storage accounts must use encryption at rest" and "AI resources only deploy to approved regions." Below this management group, you create separate subscriptions for production and development environments. The production subscription enforces strict change control and requires approval for all deployments, while the development subscription allows your data scientists flexibility to experiment with new services. This environment separation—achieved through subscription boundaries—prevents experimental work from impacting production stability while maintaining consistent security baselines through inherited policies.

## Applying resource groups for project and lifecycle boundaries

Building on this concept, resource groups provide your next level of organization. Within your production subscription, you create one resource group for each major AI project. The "customer-sentiment-production" resource group contains your ML workspace, associated compute clusters, the storage account holding training data, and the Azure AI Services instance providing text analytics. These resources share a common lifecycle: they were created together for the sentiment analysis project, they scale together as usage grows, and they'll eventually be decommissioned together when the project migrates to a new architecture. Grouping them makes permission management straightforward—grant your data science team Contributor access to this resource group, and they can work with all resources inside it without requiring individual permissions on each component.

At the same time, resource groups establish cost tracking boundaries. Azure tags each resource with its parent resource group, enabling you to generate monthly reports showing exactly how much the sentiment analysis project costs. When your finance team asks "How much did we spend on AI infrastructure last quarter?", you filter costs by resource group tags rather than manually correlating dozens of individual resource charges. This becomes especially important when your AI platform scales to support multiple projects—without resource group organization, cost attribution becomes nearly impossible. Organizations that implement consistent resource group naming conventions (for example, "rg-[project-name]-[environment]") report 60-80% faster budget reconciliation compared to ad-hoc resource naming.

:::image type="content" source="../media/azure-tags-resource-group.png" alt-text="Diagram showing how Azure tags each resource with its parent resource group.":::

However, this changes when you have shared infrastructure that multiple projects depend on. Your AI platform likely includes centralized services like a common Azure Container Registry for model images, a shared Azure Key Vault for secrets, and enterprise-wide networking components. These shared resources belong in their own "shared-services" resource group, separate from project-specific groups. This pattern—often called the hub-and-spoke model—places shared infrastructure in a hub resource group with delegated access policies, while project workloads live in spoke resource groups with more permissive experimentation policies. As you see when we explore the Microsoft Foundry Account pattern, this separation simplifies both security management and cost chargeback.

## Implementing the Microsoft Foundry Account pattern

Now that you understand basic scope organization, let's examine an advanced pattern designed specifically for AI platforms. The Microsoft Foundry Account structure establishes a hub subscription containing your shared AI infrastructure, with multiple spoke subscriptions for individual projects or business units. This architecture solves three critical challenges: it centralizes governance and cost management, it isolates project resources for security and compliance, and it enables flexible experimentation without compromising production stability.

For example, suppose your organization has five data science teams working on different AI initiatives. Instead of creating five separate hub subscriptions (which would duplicate shared infrastructure and complicate governance), you establish one Foundry hub subscription containing Azure AI Services, shared storage for datasets, enterprise networking with ExpressRoute connectivity, and centralized monitoring through Azure Monitor. Each data science team gets their own spoke subscription where they deploy project-specific ML workspaces, experiment with different compute configurations, and manage project budgets independently. The hub subscription applies organization-wide policies that inherit to all spokes, ensuring compliance, while spoke subscriptions allow team-specific policies that don't affect other projects.

This becomes especially important when your compliance requirements vary by project. Your fraud detection team must meet PCI-DSS requirements that mandate specific encryption standards and network isolation, while your customer service team works with less sensitive data under standard corporate policies. By separating these teams into different spoke subscriptions, you apply PCI-specific policies only where required without forcing unnecessary restrictions on every project. The hub subscription maintains your security baseline—encryption, regional restrictions, identity requirements—while spoke subscriptions add incremental controls based on data sensitivity. This layered governance approach reduces policy complexity by 40-50% compared to trying to accommodate all scenarios in a single subscription.

:::image type="content" source="../media/foundry-account-structure-central-hub.png" alt-text="Diagram showing a Microsoft Foundry Account structure with central hub subscription containing shared services.":::



## Scope selection criteria for production deployment

With this understanding of scope hierarchy and the Foundry pattern, consider how to choose appropriate scopes when planning your AI infrastructure. Three factors drive your scope decisions: workload isolation requirements, cost management granularity, and compliance boundaries. Workload isolation determines whether resources should share permissions and networking—production and development workloads almost always require subscription-level separation. Cost management granularity determines how detailed your budget tracking needs to be—if you need project-level chargeback, resource groups provide sufficient granularity, but if you need department-level tracking with separate Azure billing, you need subscription separation. Compliance boundaries determine where policies must differ—when data residency regulations vary by region or data classification, you typically need subscription-level boundaries to enforce different policies.

In practice, this means starting with environment separation through subscriptions (production, development, testing), then organizing projects within each environment using resource groups. If your organization has multiple business units with independent budgets and compliance requirements, add a management group layer at the top that separates units while maintaining enterprise-wide security policies. Avoid creating overly complex hierarchies—three to four levels (management group, subscription, resource group, resource) suffice for most organizations. The Azure Policy inheritance model works best when your hierarchy is shallow and wide rather than deep and narrow, because complex nested structures make troubleshooting difficult when policies conflict or unexpectedly apply.

Building on this foundation, implement consistent naming conventions that make your scope purpose immediately clear. Resource groups named "rg-customer-sentiment-prod" and "rg-customer-sentiment-dev" clearly indicate project and environment, enabling automation scripts to target appropriate scopes and helping your operations team understand resource ownership at a glance. When naming conflicts occur or you discover resource groups containing unrelated resources, these become signals that your scope design needs adjustment. Well-designed scope boundaries feel natural—team members intuitively understand which resource group should contain their new ML workspace, and policy violations are rare because the organization naturally aligns with compliance requirements.

:::image type="content" source="../media/governance-scope-hierarchy-environment.png" alt-text="Diagram showing how Azure governance scope hierarchy showing environment separation and resource organization for AI workloads with policy inheritance flow.":::


*Azure governance scope hierarchy showing environment separation and resource organization for AI workloads with policy inheritance flow*


## More resources

- [Organize your Azure resources effectively](/azure/cloud-adoption-framework/ready/azure-setup-guide/organize-resources) - Cloud Adoption Framework guidance on resource organization patterns and naming conventions
- [Azure subscription and resource group hierarchy](/azure/governance/management-groups/overview) - Detailed documentation on management group structure and policy inheritance


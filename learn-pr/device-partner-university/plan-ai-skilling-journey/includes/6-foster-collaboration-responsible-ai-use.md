True AI maturity isn't just technical—it's cultural. To sustain engagement, make AI learning both social and ethical. How you encourage collaboration and responsibility will depend on your organization's readiness level:

| **Readiness level** | **Recommended approach** | **Example actions** |
| :--- | :--- | :--- |
| **Explore** | Start with informal sharing and open dialogue. | Create a dedicated Teams channel for AI discussions. Add short "AI spotlight" moments to team meetings where early adopters share what they've tried. Encourage curiosity and normalize experimentation. |
| **Build** | Introduce recurring opportunities for collaboration and recognition. | Host monthly "AI show-and-tell" sessions or peer demos. Form a small internal community of practice. Recognize contributors publicly—badges, shout-outs, or "AI Win of the Month" posts. |
| **Optimize** | Embed collaboration and mentorship into formal programs. | Create "AI Champion" roles to mentor peers and share best practices. Maintain a repository of internal success stories and guidelines. Highlight responsible and transparent AI use as part of performance culture. |

Just as important is responsible adoption. Establish clear, role-specific guidelines for data handling, privacy, and transparency. Reinforce that using AI responsibly is everyone's job—not just IT's. Microsoft's [Responsible AI Standard](https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/final/en-us/microsoft-brand/documents/Microsoft-Responsible-AI-Standard-General-Requirements.pdf) can serve as a useful model when developing your own internal framework.

## Microsoft's Responsible AI principles

Microsoft's AI is developed around six guidelines, called the Responsible AI principles.

:::image type="content" border="true" source="../media/add-resources-to-microsoft-365-copilot-in-word.png" alt-text="Screenshot showing the location of the + arrow on Microsoft 365 Copilot in Word's inline prompt that is used to add company resources.":::

- **Fairness**: AI systems must not discriminate or exhibit bias—instead, they should treat all individuals the same.
- **Reliability and Safety**: AI systems must be robust, dependable, and safe—minimizing risks and unintended consequences.
- **Privacy and Security**: AI systems must safeguard user data and ensure privacy.
- **Inclusiveness**: AI systems must be thoughtfully designed to benefit everyone, regardless of their background, abilities, or demographics.
- **Transparency**: AI's decisions and processes must be understandable and explainable.
- **Accountability**: Developers must be held accountable for how their AI systems behave and the outcomes they create.

>[!NOTE]
> You can find more information on Microsoft's Responsible AI principles at [What is Responsible AI - Azure Machine Learning | Microsoft Learn](/azure/machine-learning/concept-responsible-ai).

Use the table to connect each Responsible AI principle to practical steps you can take when reviewing or updating your organization's AI training.

| **Principle** | **What it means in action** | **Questions or tasks to guide your update** |
| :--- | :--- | :--- |
| **Fairness** | Ensure everyone has equal access to AI tools and training. | Are our AI examples free of stereotypes or biased data? Have we checked that all roles and regions can participate in AI learning equally? When using sample data, do we include diverse, representative cases? |
| **Reliability and Safety** | Keep AI use dependable and low-risk. | Do we test AI outputs before sharing them broadly? Have we added clear guardrails or "dos and don'ts" for using generative AI? Are employees encouraged to verify AI results rather than trust them blindly? |
| **Privacy and Security** | Protect sensitive data at every step. | Do learners know what data is appropriate to share with AI tools? Are privacy warnings or examples included in training materials? Have we updated our guidance to reflect current data-handling rules? |
| **Inclusiveness** | Design AI learning that benefits everyone. | Is our content accessible to people of all abilities and learning styles?• Do examples represent a range of roles, demographics, and use cases?• Are we gathering feedback from under-represented groups? |
| **Transparency** | Make AI processes and decisions understandable. | • Do we explain how AI suggestions or outputs are generated?• Are learners encouraged to ask, "Where did this result come from?"• Do training materials include notes about data sources and limitations? |
| **Accountability** | Assign clear ownership for AI outcomes. | • Who reviews and approves new AI content or use cases?• Do employees know how to report potential misuse or errors?• Are success metrics and responsibilities documented and reviewed regularly? |

## Plan a collaborative and responsible AI moment

A strong AI culture grows when people learn *with* each other, not just from formal training. This exercise helps you design a small, low-effort initiative that encourages shared learning and reinforces responsible use.

Here are some ideas of example initiatives your organization can use at any readiness level.

| **Readiness level** | **Example initiatives** |
| :--- | :--- |
| **Explore** | • Create a Teams channel where employees can post AI tips or questions.<br>• Add a short "AI spotlight" moment to weekly meetings where early adopters share one success or lesson learned.<br>• Start an internal newsletter or chat thread summarizing interesting AI use cases found across the organization.<br>• Encourage managers to ask, "Has anyone tried using AI for this yet?" during project discussions. |
| **Build** | • Host short "AI Show-and-Tell" or lunch sessions where teams share quick demos.<br>• Form a small community of practice that meets monthly to discuss use cases and responsible AI principles.<br>• Highlight contributions publicly—through badges, shout-outs, or an "AI Win of the Month."<br>• Pair early adopters with peers who are just beginning to use AI tools. |
| **Optimize** | • Launch an "AI Champions" or peer-mentorship program that includes responsible-use guidance.<br>• Create an internal repository of AI best practices, templates, and ethical guidelines.<br>• Integrate AI collaboration milestones into performance objectives or learning dashboards.<br>• Encourage cross-department AI innovation challenges that emphasize transparency and fairness. |
